简单说下python可以做什么：
*后台开发（Django/Flask/Tornado）
*科学计算（Numpy/Scipy/Matplotlib）
*机器学习（Scikit-Learn）
*神经网络（TensorFlow）
*图像处理（Pillow）
*网络爬虫（Requests/xpath/Scrapy）

爬虫工程师能做什么？
*爬去数据，进行市场调研和商业分析（爬取知乎优质答案、抓取淘宝京东商品，评论级销量数据。。。）
*作为机器学习、数据挖掘的原始数据
*爬取优质的资源：图片、文本、视频（爬取微信公众号文章，分析新媒体内容运营策略）

对于小白来说，爬虫可能是一件非常复杂、技术门槛很高的事情。比如有人认为学爬虫必须精通python，然后系统学习python的每个知识点，很久之后发现仍然爬不了数据；有人认为先要掌握网页的智商，遂开始HTML/css，结果入了前端的坑，卒。。。
但掌握正确的方法，在短时间内做到能够爬取主流网站的数据，其实非常容易实现。但建议你从一开始就有一个具体的目标，你要爬取哪个网站的哪些数据，达到什么量级。
在目标驱动下，你的学习才会更加精准和高效。哪些所有你认为碧玺的前置知识，都是可以在完成目标的过程中学到的。
学习流程：
1、爬虫简介
2、简单爬虫架构
3、URL管理器
4、网页下载器（urllib2）
5、网页解析器（BeautifulSoup）
6、完整实例（爬取百度百科python词条相关的10000个页面数据）
  
一、爬虫简介：
爬虫是一段自动抓取互联网信息的程序（自动访问互联网并提取数据的程序）
1.1、爬虫价值：互联网数据，为我所用（如最爆笑故事App，最漂亮美女图片网、图书价格对比网等等等）

二、python简单爬虫架构：
来看一下要实现一个爬虫需要哪些方面的考虑
爬虫调度端+爬虫执行程序+有价值的数据 就是一个简单的爬虫架构
2.1、爬虫架构
（1）、爬虫调度端：
启动爬虫、停止爬虫、监视爬虫的运行情况
（2）、爬虫：
在爬虫程序中有三个模块：URL管理器——网页下载器——网页解析器（解析出的新的URL会再次传给URL管理器）会形成一个循环
《1》、URL管理器：管理已经爬取的URL和将要爬取的URL进行管理
《2》、网页下载器：从URL管理器中取出一个将要爬取的URL将其传送给网页下载器
             URL下载器会将网页下载下来，存储成为一段字符串
《3》、字符串会传送给网页解析器进行解析
             解析器一方面会解析出有价值的数据，另一方面，每个网页都有指向其他网页
             的URL，这些URL被解析出来后会补充给URL管理器
（3）、有价值的数据

三、python爬虫URL管理：
URL管理器：用来管理待抓取的URL集合和已抓取的URL集合
管理器的意义：为了防止重复抓取和循环抓取
3.1、URL管理器需要支持的功能：
《1》、添加新的URL到待爬取的集合中
《2》、在添加之前需要判断这个URL师傅已经在集合中
《3》、需要支持获取待爬取的URL功能
《4》、在获取待爬取的URL之后需要判断是否还有待爬取的URL。
《5》、获取待爬取的URL之后，需要把这个URL从待爬取的URL集合里面移动到已爬取的URL集合中。
3.2、URL管理器的实现方式：
目前有三种实现方式：
（1）、我们直接将待爬取的URL集合和已爬取的URL集合存储到内存中。
python内存：待爬取URL集合：set()   已爬取URL集合:set()
为什么选择set呢？是因为python的set中可以直接去除重复的元素
（2）、将URL存储在关系数据库中：
比如mysql。我们可以建立一个表：urls（url, is_crawled）
